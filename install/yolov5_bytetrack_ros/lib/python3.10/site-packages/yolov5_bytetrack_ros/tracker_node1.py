import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import Twist
from cv_bridge import CvBridge
import cv2
import torch
import sys
import numpy as np
from types import SimpleNamespace

# ä¸´æ—¶ä¿®å¤ numpy è­¦å‘Š
np.float = float

# åŠ è½½ YOLOv5 å’Œ ByteTrack è·¯å¾„
sys.path.append('/home/jf/tello_tracking_ws/src/yolov5')
sys.path.append('/home/jf/tello_tracking_ws/src/ByteTrack')

from models.common import DetectMultiBackend
from utils.general import non_max_suppression
from utils.augmentations import letterbox
from yolox.tracker.byte_tracker import BYTETracker


def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    coords = coords.clone()
    if ratio_pad is None:
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])
        pad = ((img1_shape[1] - img0_shape[1] * gain) / 2,
               (img1_shape[0] - img0_shape[0] * gain) / 2)
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    coords[:, [0, 2]] -= pad[0]
    coords[:, [1, 3]] -= pad[1]
    coords[:, :4] /= gain
    coords[:, :4] = coords[:, :4].clamp(0)
    return coords


class PIDController:
    def __init__(self, kp, ki, kd, setpoint=0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.setpoint = setpoint
        self.prev_error = 0
        self.integral = 0

    def update(self, measurement):
        error = self.setpoint - measurement
        self.integral += error
        derivative = error - self.prev_error
        self.prev_error = error
        return self.kp * error + self.ki * self.integral + self.kd * derivative


class TrackerNode(Node):
    def __init__(self):
        super().__init__('tracker_node')
        self.bridge = CvBridge()

        weights = 'yolov5s.pt'
        self.img_size = 640
        self.device = torch.device('cpu')

        self.get_logger().info("ğŸ”§ åŠ è½½ YOLOv5 æ¨¡å‹ä¸­...")
        self.model = DetectMultiBackend(weights, device=self.device)
        self.model.eval()
        self.stride = int(self.model.stride)
        self.get_logger().info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œstride = {self.stride}")

        self.get_logger().info("ğŸ”§ åˆå§‹åŒ– ByteTrack ä¸­...")
        self.tracker = BYTETracker(
            SimpleNamespace(
                track_thresh=0.5,
                track_buffer=30,
                match_thresh=0.8,
                min_box_area=10,
                mot20=False
            ),
            frame_rate=30
        )
        self.get_logger().info("âœ… ByteTrack åˆå§‹åŒ–å®Œæˆ")

        self.pid_x = PIDController(kp=0.005, ki=0.0, kd=0.001)
        self.pid_y = PIDController(kp=0.005, ki=0.0, kd=0.001)

        self.subscription = self.create_subscription(Image, '/tello/image_raw', self.image_callback, 10)
        self.result_pub = self.create_publisher(Image, '/yolo/image_out', 10)
        self.cmd_pub = self.create_publisher(Twist, '/tello/cmd_vel', 10)

        self.get_logger().info("âœ… YOLOv5 + ByteTrack + PID æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        self.get_logger().info("ğŸ“¸ æ­£åœ¨è®¢é˜… /tello/image_raw")

    def image_callback(self, msg):
        try:
            self.get_logger().info("ğŸ“¥ æ”¶åˆ°å›¾åƒå¸§")
            frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            self.get_logger().info(f"ğŸ“ å›¾åƒå°ºå¯¸: {frame.shape}")
            img_h, img_w = frame.shape[:2]

            img = letterbox(frame, self.img_size, stride=self.stride, auto=True)[0]
            img = img[:, :, ::-1].transpose(2, 0, 1)
            img = np.ascontiguousarray(img)
            self.get_logger().info("ğŸ§® å›¾åƒé¢„å¤„ç†å®Œæˆ")

            img_tensor = torch.from_numpy(img).to(self.device).float() / 255.0
            if img_tensor.ndimension() == 3:
                img_tensor = img_tensor.unsqueeze(0)
            self.get_logger().info("ğŸ”„ å›¾åƒè½¬æ¢ä¸ºTensorå®Œæˆ")

            with torch.no_grad():
                pred = self.model(img_tensor, augment=False, visualize=False)
            self.get_logger().info("ğŸ§  æ¨¡å‹æ¨ç†å®Œæˆ")

            pred = non_max_suppression(pred, 0.25, 0.45, classes=None, agnostic=False)[0]
            self.get_logger().info(f"ğŸ“¦ NMSæ£€æµ‹åˆ° {len(pred) if pred is not None else 0} ä¸ªç›®æ ‡")

            dets = []
            if pred is not None and isinstance(pred, torch.Tensor) and len(pred) > 0:
                pred[:, :4] = scale_coords(img_tensor.shape[2:], pred[:, :4], frame.shape).round()
                for *xyxy, conf, cls in pred:
                    x1, y1, x2, y2 = map(int, xyxy)
                    dets.append([x1, y1, x2, y2, float(conf), int(cls)])
            self.get_logger().info(f"ğŸ“Š æœ‰æ•ˆæ£€æµ‹æ¡†æ•°é‡: {len(dets)}")

            if len(dets) > 0:
                dets_np = np.array(dets)[:, :5].astype(np.float32) 
                dets_tensor = torch.from_numpy(dets_np).to(self.device)  # âœ… è½¬ä¸º tensor
                img_h, img_w = frame.shape[:2]
                self.get_logger().info(f"ğŸ“¡ è°ƒç”¨ByteTrackæ›´æ–°: dets.shape={dets_np.shape}")
                online_targets = self.tracker.update(
                    output_results=dets_tensor,
                    img_info=(img_h, img_w),
                    img_size=(img_h, img_w)
                )

                self.get_logger().info(f"ğŸ§ å½“å‰è·Ÿè¸ªå¯¹è±¡æ•°é‡: {len(online_targets)}")

                if len(online_targets) > 0:
                    for track in online_targets:
                        tlwh = track.tlwh
                        track_id = track.track_id
                        x1, y1, w, h = map(int, tlwh)
                        x2, y2 = x1 + w, y1 + h
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(frame, f'ID: {track_id}', (x1, y1 - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

                    track = online_targets[0]
                    x1, y1, w, h = map(int, track.tlwh)
                    cx, cy = x1 + w // 2, y1 + h // 2
                    center_x, center_y = img_w // 2, img_h // 2

                    error_x = cx - center_x
                    error_y = cy - center_y
                    vel_msg = Twist()
                    vel_msg.linear.y = float(self.pid_x.update(error_x))  # å·¦å³ç§»åŠ¨
                    vel_msg.linear.z = float(self.pid_y.update(error_y))  # ä¸Šä¸‹ç§»åŠ¨
                    self.cmd_pub.publish(vel_msg)
                    self.get_logger().info(f"ğŸ® å‘å¸ƒæ§åˆ¶æŒ‡ä»¤: vy={vel_msg.linear.y:.2f}, vz={vel_msg.linear.z:.2f}")
                else:
                    self.get_logger().info("ğŸš« å½“å‰å¸§æœªæ£€æµ‹åˆ°ä»»ä½•å¯è·Ÿè¸ªç›®æ ‡")

            result_msg = self.bridge.cv2_to_imgmsg(frame, encoding="bgr8")
            self.result_pub.publish(result_msg)
            self.get_logger().info("ğŸ“¤ å‘å¸ƒæ ‡æ³¨å›¾åƒåˆ° /yolo/image_out")

        except Exception as e:
            self.get_logger().error(f"âŒ å¤„ç†å›¾åƒå‡ºé”™: {e}")


def main(args=None):
    rclpy.init(args=args)
    node = TrackerNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

