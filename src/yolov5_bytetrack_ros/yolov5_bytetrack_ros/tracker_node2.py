import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import Twist
from cv_bridge import CvBridge
import cv2
import torch
import sys
import numpy as np
from types import SimpleNamespace

np.float = float  # ä¸´æ—¶ä¿®å¤ numpy è­¦å‘Š

sys.path.append('/home/jf/tello_tracking_ws/src/yolov5')
sys.path.append('/home/jf/tello_tracking_ws/src/ByteTrack')

from models.common import DetectMultiBackend
from utils.general import non_max_suppression
from utils.augmentations import letterbox
from yolox.tracker.byte_tracker import BYTETracker


def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    coords = coords.clone()
    if ratio_pad is None:
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])
        pad = ((img1_shape[1] - img0_shape[1] * gain) / 2,
               (img1_shape[0] - img0_shape[0] * gain) / 2)
    else:
        gain = ratio_pad[0][0]
        pad = ratio_pad[1]

    coords[:, [0, 2]] -= pad[0]
    coords[:, [1, 3]] -= pad[1]
    coords[:, :4] /= gain
    coords[:, :4] = coords[:, :4].clamp(0)
    return coords


class PIDController:
    def __init__(self, kp, ki, kd, setpoint=0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.setpoint = setpoint
        self.prev_error = 0
        self.integral = 0

    def update(self, measurement):
        error = self.setpoint - measurement
        self.integral += error
        derivative = error - self.prev_error
        self.prev_error = error
        return self.kp * error + self.ki * self.integral + self.kd * derivative


class TrackerNode(Node):
    def __init__(self):
        super().__init__('tracker_node')
        self.bridge = CvBridge()

        weights = 'yolov5s.pt'
        self.img_size = 640
        self.device = torch.device('cpu')

        self.get_logger().info("ğŸ”§ åŠ è½½ YOLOv5 æ¨¡å‹ä¸­...")
        self.model = DetectMultiBackend(weights, device=self.device)
        self.model.eval()
        self.stride = int(self.model.stride)
        self.get_logger().info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œstride = {self.stride}")

        self.get_logger().info("ğŸ”§ åˆå§‹åŒ– ByteTrack ä¸­...")
        self.tracker = BYTETracker(
            SimpleNamespace(
                track_thresh=0.5,
                track_buffer=30,
                match_thresh=0.8,
                min_box_area=10,
                mot20=False
            ),
            frame_rate=30
        )
        self.get_logger().info("âœ… ByteTrack åˆå§‹åŒ–å®Œæˆ")

        # PID æ§åˆ¶å™¨
        self.pid_x = PIDController(kp=0.15, ki=0.0, kd=0.001)
        self.pid_y = PIDController(kp=0.15, ki=0.0, kd=0.001)

        self.cmd_pub = self.create_publisher(Twist, '/tello/cmd_vel', 10)
        self.subscription = self.create_subscription(Image, '/tello/image_raw', self.image_callback, 10)
        self.result_pub = self.create_publisher(Image, '/yolo/image_out', 10)

    def image_callback(self, msg):
        try:
            self.get_logger().info("ğŸ“¥ æ”¶åˆ°å›¾åƒå¸§")
            frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            img_h, img_w = frame.shape[:2]
            self.get_logger().info(f"ğŸ–¼ å›¾åƒå°ºå¯¸: {img_w}x{img_h}")

            # YOLOv5 é¢„å¤„ç†
            img = letterbox(frame, self.img_size, stride=self.stride, auto=True)[0]
            img = img[:, :, ::-1].transpose(2, 0, 1)
            img = np.ascontiguousarray(img)
            self.get_logger().info("ğŸ“¦ å›¾åƒé¢„å¤„ç†å®Œæˆ")

            img_tensor = torch.from_numpy(img).to(self.device).float() / 255.0
            if img_tensor.ndimension() == 3:
                img_tensor = img_tensor.unsqueeze(0)
            self.get_logger().info("ğŸ” å¼€å§‹æ¨ç†...")

            with torch.no_grad():
                pred = self.model(img_tensor, augment=False, visualize=False)

            self.get_logger().info("ğŸ“¤ æ¨ç†å®Œæˆï¼Œè¿›è¡Œ NMS")
            pred = non_max_suppression(pred, 0.25, 0.45, classes=None, agnostic=False)[0]

            dets = []
            if pred is not None and isinstance(pred, torch.Tensor) and len(pred) > 0:
                pred[:, :4] = scale_coords(img_tensor.shape[2:], pred[:, :4], frame.shape).round()
                for *xyxy, conf, cls in pred:
                    x1, y1, x2, y2 = map(int, xyxy)
                    dets.append([x1, y1, x2, y2, float(conf), int(cls)])
                self.get_logger().info(f"ğŸ” æ£€æµ‹åˆ° {len(dets)} ä¸ªç›®æ ‡")

            if len(dets) > 0:
                dets_np = np.array(dets)[:, :5].astype(np.float32)
                dets_tensor = torch.from_numpy(dets_np).to(self.device)
                online_targets = self.tracker.update(dets_tensor, (img_h, img_w), (img_h, img_w))
                self.get_logger().info(f"ğŸ¯ è·Ÿè¸ªåˆ° {len(online_targets)} ä¸ªç›®æ ‡")

                if len(online_targets) > 0:
                    for track in online_targets:
                        x1, y1, w, h = map(int, track.tlwh)
                        x2, y2 = x1 + w, y1 + h
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(frame, f'ID: {track.track_id}', (x1, y1 - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

                    # æ§åˆ¶é€»è¾‘
                    track = online_targets[0]
                    x1, y1, w, h = map(int, track.tlwh)
                    cx, cy = x1 + w // 2, y1 + h // 2
                    center_x, center_y = img_w // 2, img_h // 2

                    error_x = cx - center_x
                    error_y = cy - center_y
                    self.get_logger().info(f"ğŸ¯ ä¸­å¿ƒè¯¯å·®: X={error_x}, Y={error_y}")

                    vy = float(self.pid_x.update(error_x))
                    vz = float(self.pid_y.update(error_y))
                    vy = max(min(vy, 100), -100)
                    vz = max(min(vz, 100), -100)

                    twist_msg = Twist()
                    twist_msg.linear.x = 0.0
                    twist_msg.linear.y = vy/100 
                    twist_msg.linear.z = vz/100 
                    twist_msg.angular.z = 0.0
                    self.cmd_pub.publish(twist_msg)
                    self.get_logger().info(f"ğŸš å‘å¸ƒé€Ÿåº¦ï¼šY={vy}, Z={vz}")
                else:
                    self.get_logger().info("ğŸš« å½“å‰å¸§æœªæ£€æµ‹åˆ°ä»»ä½•å¯è·Ÿè¸ªç›®æ ‡")
                    self._publish_stop()

            else:
                self.get_logger().info("ğŸš« å½“å‰å¸§æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
                self._publish_stop()

            result_msg = self.bridge.cv2_to_imgmsg(frame, encoding="bgr8")
            self.result_pub.publish(result_msg)

        except Exception as e:
            self.get_logger().error(f"âŒ å¤„ç†å›¾åƒå‡ºé”™: {e}")

    def _publish_stop(self):
        twist_msg = Twist()
        twist_msg.linear.x = 0.0
        twist_msg.linear.y = 0.0
        twist_msg.linear.z = 0.0
        twist_msg.angular.z = 0.0
        self.cmd_pub.publish(twist_msg)
        self.get_logger().info("ğŸ›‘ å‘å¸ƒåœæ­¢å‘½ä»¤")

    def destroy_node(self):
        self._publish_stop()
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    node = TrackerNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()

